{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximate Bayesian inference\n",
    "This notebook demonstrates how to compute various approximations of the Fisher information matrix from (pre-trained) PyTorch models (e.g. *torchvision* models pretrainted on ImageNet) which can be used as preconditioners in second-order optimization or to perform approximate Bayesian inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchvision\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# From the repository\n",
    "from curvature import fisher, plot\n",
    "from curvature.sampling import invert_factors, sample_and_replace_weights\n",
    "from curvature.utils import calibration_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "After import a required modules, let's define some helper functions, the model and data we want to use and train the model (or use a pre-trained one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to 'cuda' if you have a working GPU.\n",
    "device = 'cpu'\n",
    "\n",
    "def train(model, data, criterion, optimizer, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for images, labels in tqdm(data):\n",
    "            logits = model(images.to(device))\n",
    "\n",
    "            loss = criterion(logits, labels.to(device))\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "def eval(model, data):\n",
    "    model.eval()\n",
    "    logits = torch.Tensor().to(device)\n",
    "    targets = torch.LongTensor()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(data):\n",
    "            logits = torch.cat([logits, model(images.to(device))])\n",
    "            targets = torch.cat([targets, labels])\n",
    "    return torch.nn.functional.softmax(logits, dim=1), targets\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "    print(f\"Accuracy: {100 * np.mean(np.argmax(predictions.cpu().numpy(), axis=1) == labels.numpy()):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a PyTorch model (or load a pretrained one).\n",
    "class Flatten(torch.nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "# This tutorial uses a LeNet-5 variant.\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 6, 5, padding=2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(2, 2),\n",
    "    torch.nn.Conv2d(6, 16, 5),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(2, 2),\n",
    "    Flatten(),\n",
    "    torch.nn.Linear(16 * 5 * 5, 120),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(120, 84),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(84, 10)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some data for training\n",
    "torch_data = \"~/.torch/datasets\"  # Standard PyTorch dataset location\n",
    "train_set = torchvision.datasets.MNIST(root=torch_data,\n",
    "                                       train=True,\n",
    "                                       transform=torchvision.transforms.ToTensor(),\n",
    "                                       download=True)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32)\n",
    "\n",
    "# And some for evaluating/testing\n",
    "test_set = torchvision.datasets.MNIST(root=torch_data,\n",
    "                                      train=False,\n",
    "                                      transform=torchvision.transforms.ToTensor(),\n",
    "                                      download=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model (or load a pretrained one)\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "train(model, train_loader, criterion, optimizer, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model (optional)\n",
    "sgd_predictions, sgd_labels = eval(model, test_loader)\n",
    "accuracy(sgd_predictions, sgd_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The diagonal Fisher information matrix (IM)\n",
    "Now we can compute the simplest curvature approximation: The diagonal Fisher information matrix (IM). This is done in a very similar way to a standard PyTorch training loop, except that we sample our labels from the output distribution\n",
    "of the trained model to obtain the IM instead of the 'empirical' IM which uses labels from the data distribution and replace the optimizer by the update of our curvature estimator.\n",
    "\n",
    "This will give a rank-1 approximation of the IM. If a better approximation is desired, use more samples from the model output distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "diag = fisher.DIAG(model)\n",
    "\n",
    "for images, labels in tqdm(train_loader):\n",
    "    logits = model(images.to(device))\n",
    "    dist = torch.distributions.Categorical(logits=logits)\n",
    "    \n",
    "    # A rank-10 diagonal IM approximation.\n",
    "    for sample in range(10):\n",
    "        labels = dist.sample()\n",
    "        \n",
    "        loss = criterion(logits, labels)\n",
    "        model.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "\n",
    "        diag.update(batch_size=images.size(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kronecker factorization\n",
    "We can also compute the Kronecker factored IM (KFAC). The module interface is exactly the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfac = fisher.KFAC(model)\n",
    "\n",
    "for images, labels in tqdm(train_loader):\n",
    "    logits = model(images.to(device))\n",
    "    dist = torch.distributions.Categorical(logits=logits)\n",
    "    \n",
    "    # A rank-1 Kronecker factored IM approximation.\n",
    "    labels = dist.sample()\n",
    "    \n",
    "    loss = criterion(logits, labels)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    kfac.update(batch_size=images.size(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigenvalue correction\n",
    "To compute the sparse information form of the IM, we first need to compute the eigenvalue corrected diagonal (EFB), which in turn requires the KFAC factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = list(kfac.state.values())\n",
    "efb = fisher.EFB(model, factors)\n",
    "\n",
    "for images, labels in tqdm(train_loader):\n",
    "    logits = model(images.to(device))\n",
    "    dist = torch.distributions.Categorical(logits=logits)\n",
    "    \n",
    "    for sample in range(10):\n",
    "        labels = dist.sample()\n",
    "        \n",
    "        loss = criterion(logits, labels)\n",
    "        model.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "    \n",
    "        efb.update(batch_size=images.size(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Information Form\n",
    "The final step is the computation of the diagonal correction term D. This does not involve any data. Further, we can choose the rank of the approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = list(efb.state.values())\n",
    "diags = list(diag.state.values())\n",
    "inf = fisher.INF(factors, lambdas, diags)\n",
    "inf.accumulate(rank=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inversion and Sampling\n",
    "By inverting the IM approximation, we obtain an approximate weight posterior distribution of our model. Because the approximation is inaccurate, we need to regularize it with the two hyperparameters `N` (scale) and `tau` (norm).\n",
    "\n",
    "To transform our model into a Baysian Neural Network (BNN), we can now simply sample weights from the approximate posterior. Instead of single forward pass, we than perform multiple and average the results referred to as 'approximate Bayesian inference' or 'Monte Carlo integration'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = 'inf'\n",
    "norm = 1e8\n",
    "scale = 2e10\n",
    "inv_factors = invert_factors(inf.state, norm, scale, estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_mean = copy.deepcopy(model.state_dict())\n",
    "mean_predictions = 0\n",
    "samples = 10  # 10 Monte Carlo samples from the weight posterior.\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sample in range(samples):\n",
    "        sample_and_replace_weights(model, inv_factors, estimator)\n",
    "        predictions, labels = eval(model, test_loader)\n",
    "        mean_predictions += predictions\n",
    "        model.load_state_dict(posterior_mean)\n",
    "    mean_predictions /= samples\n",
    "    \n",
    "accuracy(mean_predictions, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration\n",
    "The obtained averaged model output can now be compared against the single determinstic forward pass of the standard model. Here we only have a look at the calibration. For this simple model and dataset, the baseline is already very well calibrated and there is practically no difference between the it and the Bayesian model, especially as we did not perform any hyperparameter search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ece_nn = calibration_curve(sgd_predictions.cpu().numpy(), sgd_labels.numpy())[0]\n",
    "ece_bnn = calibration_curve(mean_predictions.cpu().numpy(), labels.numpy())[0]\n",
    "print(f\"ECE NN: {100 * ece_nn:.2f}%, ECE BNN: {100 * ece_bnn:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, nrows=1, figsize=(12, 6), tight_layout=True)\n",
    "ax[0].set_title('SGD', fontsize=16)\n",
    "ax[1].set_title('INF-Laplace', fontsize=16)\n",
    "plot.reliability_diagram(sgd_predictions.cpu().numpy(), sgd_labels.numpy(), axis=ax[0])\n",
    "plot.reliability_diagram(mean_predictions.cpu().numpy(), labels.numpy(), axis=ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 7), tight_layout=True)\n",
    "c1 = next(ax._get_lines.prop_cycler)['color']\n",
    "c2 = next(ax._get_lines.prop_cycler)['color']\n",
    "plot.calibration(sgd_predictions.cpu().numpy(), sgd_labels.numpy(), color=c1, label=\"SGD\", axis=ax)\n",
    "plot.calibration(mean_predictions.cpu().numpy(), labels.numpy(), color=c2, label=\"INF-Laplace\", axis=ax)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test] *",
   "language": "python",
   "name": "conda-env-test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
